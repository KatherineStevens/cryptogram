#Cryptogram

##Creating and Decrypting
This code can create a cryptogram (monoalphabetic substitution cipher) from a given text file. It will solve the cryptogram given a training text. The length that these texts should be is not exact. For my own tests, I used training text ranging from about 600 - 85,000 words, and the cipher text should be longer than about 65 words.

##Writing the Code
While visiting my parents, I sat with my family as all of us worked on our copy of the cryptogram from the newspaper. Discussing with my partner the technique I used to solve this particular puzzle, I realized that there was a distinct and repeating pattern to decrypting it. For anyone who is unfamiliar, a cryptogram is a substitution cipher for which the key is a mapping from one letter in the alphabet to a single random other letter. The decryption process is as follows: With my general intuition of how often letters appear in the English language, I start by looking for the most common ones. I look for familiar pairs as well, which could be something like “-oo-” or “-ing”. As part of this preliminary scan, I also look for groupings of letters that could potentially be common words, for example “a” or “the”. I think through a few different options, I make a guess for a letter or a word, and then observe the words that begin to form. I look for whether groups of letters start to look like real words, or if a group is moving toward a non-existent word. Based on my results I either continue with the process, or move backwards and re-evaluate some letters I guessed. This process is repeated until the phrase is made up of real words.

I have seen many examples of sudoku solvers coded, but I haven’t come across a cryptogram solver. My partner and I thought this would be a neat project to try out. I did some research and found that this would take some machine learning techniques, which made it even more appealing to me. I set a plan to make an algorithm to solve the puzzle. We decided to start by having my partner create the necessary classes as I worked on coding the algorithm. In this blog, I will discuss my own work on creating the decryption code. 

To start, I listed all the variables and functions I expected to need to solve this. I needed a training text to teach my program from. Just like using what I know about letter frequencies to solve the newspaper cryptogram, my program needed some knowledge as well. It needed to learn how often letters should occur in English, and furthermore, how often pairs of letters occur. This is where the training text comes in. The initial guess for the key would be made by mapping the letters of the training text to those of the cipher text based on the similar single letter frequencies of each. I needed to make a function that returns the single frequencies given a text, and a function that produces an initial key guess given the single letter frequencies of the training text and cipher text. Below is a graph of the single letter frequencies of an arbitrary English sample text. It can be seen from this that spaces obviously are the most frequent, followed by “E” and “T”.

<figure>
        <a href="/img/single_freq.png"><img src="/img/single_freq.png"></a>
</figure>

For pairs of letters, I needed to make a function that calculates bigram frequencies of a given text, and returns a matrix of those frequencies. Here, the matrix rows and columns consist of each letter in the English alphabet and space. A bigram consists of two consecutive letters or letter and space, i.e. a pairing of row and column elements. The function reads through the text, and for each occurrence of a specific row-column pair, increments that corresponding element in the return matrix by one. To explain why I chose to include the space along with the alphabet in these frequency measurements, I wanted my cryptogram to mimic the ones in the newspaper. The spaces would not be substituted and space automatically maps to space in the key. I used them, however, because I thought it would be useful to know how often letters are at the beginning and end of words, along with the frequency of pairs of letters. I used a heatmap (below) to show a visual representation of these frequencies from an arbitrary sample of English text. The hottest (most frequent) pairs are “E” and space, and space and “T”. This makes sense since “E” and “T” were the most common single frequency letters. Then the next most frequent pairs I noticed were “TH”, “HE”, “D”- space, and space -“A”. Which also makes sense since words like “the” and “and” are common. 

<figure>
        <a href="/img/freq.png"><img src="/img/freq.png"></a>
</figure>x

My partner @tylovejoy made Key, Quote and Cryptogram classes. The Key class has a mapping function which returns a dictionary that randomly assigns each letter of the alphabet to a different unique letter of the alphabet. The Quote class is the uppercase version of the original quote used to create the cryptogram. The Cryptogram class has attributes Key, Quote, the string of the cryptogram itself, and an encryption function that uses the given key and quote to create the cipher. Now that I had an encryption function, I needed a decryption function that would take in as parameters a key and a cipher, and would return the decrypted text after applying that key to that cipher. 

When solving a cryptogram on paper, I use my own vocabulary to check if I am getting further or closer to real words. I needed a way for the program to measure if it is getting closer to the solution. This is where the bigram frequencies are useful. By finding the difference between each element in the bigram of the training text and each element of the bigram of a given cipher and summing these values, you can calculate a number that can then be compared to this calculation in the next iteration. Since we want the closest bigram frequencies to the training text bigram frequencies, we want this value to be minimized. Although this seems intuitive, the reason this function works can be shown mathematically. In short, if we assume the bigram frequencies are normally distributed and independent of each other, then minimizing our function is actually equivalent to maximizing the joint probability density function of these elements (independent and identically distributed normal random variables). If you are interested in more detail of the mathematical explanation of why minimizing this function works, please refer to my source1 below. 

The algorithm would start with an initial key guess based on single letter frequencies. Then it would calculate a current bigram matrix by decrypting the cipher using the current key. It then evaluates the difference between the current bigram matrix and the expected bigram matrix (the bigram matrix of the training text). Then it creates a temporary key, which copies the current key and switches two of the mapped letters. The difference is now measured between a new bigram matrix, using this temporary key, and the expected bigram matrix. If the difference is now less, then we want to keep the change to the key. If the difference is more or equal, then we throw out that change to the key and continue trying swaps.

At this point, the algorithm worked well when the cipher text was relatively long, and the training text was relatively short. To my surprise, the code would stop decrypting properly when the training text was very long. It also had issues when I tried shortening the cipher text past a certain length. I figured that the great differences when comparing counts in the training text matrix to those in the cipher text matrix may have been producing insignificant results, causing my algorithm to plateau. To resolve this, I kept the long training text, but divided all the counts of the training text matrix by the ratio between the length of the training text and the length of the cipher. This improved the decrypted text, but did not fix it completely. I realized that with this algorithm, and my desired lengths of texts, this was the best using bigrams would do, so I added a trigram function that did the same thing as the bigram function, but now would count trigram frequencies throughout a given text. With these changes, the code was able to perform successfully on smaller ciphers and a large training text. I tried tetragrams as well, however the program took much longer to run and did not noticeably improve the cipher. To continue to improve the code, I would like to try to implement common words as well. 

##Sources
1. https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.55.89&rep=rep1&type=pdf

2. https://www.youtube.com/watch?v=pF-DzPOCeM8


